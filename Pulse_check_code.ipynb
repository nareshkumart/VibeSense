{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "5ceca964",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T06:26:23.944415Z",
     "start_time": "2023-04-11T06:26:13.734929Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: virtualenv in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (20.21.0)\n",
      "Requirement already satisfied: platformdirs<4,>=2.4 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from virtualenv) (2.5.2)\n",
      "Requirement already satisfied: distlib<1,>=0.3.6 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from virtualenv) (0.3.6)\n",
      "Requirement already satisfied: filelock<4,>=3.4.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from virtualenv) (3.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install virtualenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "b1ecde42",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T06:28:46.114039Z",
     "start_time": "2023-04-11T06:28:45.452846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "conda activate pulse_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cbc60a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T06:29:39.347338Z",
     "start_time": "2023-04-11T06:29:34.931317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-docx in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (0.8.11)\n",
      "Requirement already satisfied: lxml>=2.3.2 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from python-docx) (4.9.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install python-docx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "60b7c988",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T06:29:45.857191Z",
     "start_time": "2023-04-11T06:29:42.190746Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: wordcloud in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: pillow in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from wordcloud) (9.2.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from wordcloud) (3.7.1)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from wordcloud) (1.24.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (5.12.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (1.0.7)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from matplotlib->wordcloud) (4.25.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib->wordcloud) (3.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87a18aa4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-11T06:29:54.393345Z",
     "start_time": "2023-04-11T06:29:49.992300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (0.17.1)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from textblob) (3.7)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
      "Requirement already satisfied: click in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (4.64.1)\n",
      "Requirement already satisfied: joblib in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from nltk>=3.1->textblob) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages (from click->nltk>=3.1->textblob) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -cipy (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -atplotlib (c:\\users\\nareshkumar.t\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c890826",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:39.588638Z",
     "start_time": "2023-05-17T12:05:36.222798Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     C:\\Users\\Nareshkumar.T\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Nareshkumar.T\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import docx\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "#For word cloud\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from ipywidgets import interact\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "#Import NLP libraries for sentiment analysis\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob\n",
    "\n",
    "# For Classfication\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ed4d0b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:41.204591Z",
     "start_time": "2023-05-17T12:05:41.188507Z"
    }
   },
   "outputs": [],
   "source": [
    "def createtable(address):\n",
    "    '''\n",
    "    File name should be in a specific format as \n",
    "    '16th_PulseCheckMeeting_Group6_2023-03-15.docx'\n",
    "    16th - number of plus check meeting\n",
    "    PulseCheckMeeting - Name of the meeting\n",
    "    Group6 - Group Number\n",
    "    Date of meeting\n",
    "    '''\n",
    "    #Read the documents\n",
    "    doc = docx.Document(address)\n",
    "\n",
    "    #Read the document Name\n",
    "    file_name = os.path.basename(address)\n",
    "    values = file_name.split('_')\n",
    "    \n",
    "    #Create Data Dictionary\n",
    "    data = {'Meeting_ID':[values[0]], 'Meeting':[values[1]],'Group':[values[2]], 'Date' :[values[3][:-5]]}\n",
    "\n",
    "    #Create a New dataframe\n",
    "    #df = pd.DataFrame(data, index=False)\n",
    "    df = pd.DataFrame(data)\n",
    "    \n",
    "    #Convert the text data into text paragraphs\n",
    "    text_para = []\n",
    "    for para in doc.paragraphs:\n",
    "        text_para.append(para.text)\n",
    "    \n",
    "    #From Text Data Extract Time stamp, name of speaker and the text\n",
    "    time_stamp = []\n",
    "    Speaker_Name = []\n",
    "    Speaker_text = []\n",
    "    for i in text_para:\n",
    "        val = i.split('\\n')\n",
    "        time_stamp.append(val[0])\n",
    "        Speaker_Name.append(val[1])\n",
    "        Speaker_text.append(val[2])\n",
    "    \n",
    "    data_dict = {'time_stamp' : time_stamp, 'Speaker_Name': Speaker_Name, 'Speaker_text' : Speaker_text}\n",
    "\n",
    "    #Create a New dataframe based on text values extracted above\n",
    "    New_df = pd.DataFrame(data_dict)\n",
    "\n",
    "    #concat with the dataframe and forward fill the values\n",
    "    df = pd.concat([df, New_df], axis = 1)\n",
    "    df.fillna(method = 'ffill', inplace = True)\n",
    "\n",
    "    #Create a New column as set\n",
    "    df['set'] = df.groupby('Speaker_Name').cumcount()+1\n",
    "    \n",
    "    #From Timestamp find the time in seconds speaker speek\n",
    "    time_min = []\n",
    "    time_max = []\n",
    "    for i in range(len(df['time_stamp'])):\n",
    "        A = df['time_stamp'][i]\n",
    "        V = A.split(' --> ')\n",
    "        t_min = V[0].split(':')\n",
    "        t_max = V[1].split(':')\n",
    "        time_min.append(float(t_min[0])*3600 + float(t_min[1])*60 + float(t_min[2]))\n",
    "        time_max.append(float(t_max[0])*3600 + float(t_max[1])*60 + float(t_max[2]))\n",
    "    \n",
    "    time_diff_seconds = [time_max[i] - time_min[i] for i in range(len(time_min))]\n",
    "    #Create a new column as time in seconds\n",
    "    df['time_seconds'] = time_diff_seconds\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86a32daf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:41.767090Z",
     "start_time": "2023-05-17T12:05:41.746210Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentimenttextlength(df):\n",
    "    #Merge the text Data based on Meeting ID and Text column\n",
    "    sentiment_df = df.groupby(['Meeting_ID','Group','Speaker_Name'])['Speaker_text'].agg(' '.join).reset_index()\n",
    "    # Find the lengh of text based on each speaker\n",
    "    # Some speaker never spoke during the call, so to remove null we are adding hello as dummy text for all non speaker\n",
    "    sentiment_df['Speaker_text'] = [s if s.lower().startswith(\"hello\") else 'hello' +' '+ s for s in list(sentiment_df['Speaker_text'])] \n",
    "    # calculate the length of each row\n",
    "    row_lengths = sentiment_df['Speaker_text'].str.len()\n",
    "    # calculate the total length of all rows\n",
    "    total_length = row_lengths.sum()\n",
    "    # calculate the percentage of text in each row\n",
    "    percentages = row_lengths/total_length * 100\n",
    "    # add the column into the dataframe\n",
    "    sentiment_df['text_percentage'] = percentages\n",
    "    return sentiment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ab1ec0b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:42.127346Z",
     "start_time": "2023-05-17T12:05:42.106222Z"
    }
   },
   "outputs": [],
   "source": [
    "def time_spent(df):\n",
    "    #Sum the time (in seconds) based on meeting ID and Speaker_Name\n",
    "    time_df = df.groupby(['Meeting_ID','Group','Speaker_Name'])['time_seconds'].agg('sum').reset_index()\n",
    "    final_df = pd.DataFrame()\n",
    "    for i in list(time_df['Meeting_ID'].unique()):\n",
    "        temp_df = time_df[time_df['Meeting_ID'] == i].reset_index(drop = True)\n",
    "        for j in list(temp_df['Group'].unique()):\n",
    "            temp_df1 = temp_df[temp_df['Group'] == j].reset_index(drop = True)\n",
    "            total = temp_df1['time_seconds'].sum()\n",
    "            temp_df1['time_percentage'] = [(temp_df1['time_seconds'][i]/total)*100 for i in range(len(temp_df1))]\n",
    "            final_df = final_df.append(temp_df1,ignore_index = True)\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7169d52e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:42.487471Z",
     "start_time": "2023-05-17T12:05:42.456770Z"
    }
   },
   "outputs": [],
   "source": [
    "def key_points(df, level):\n",
    "    '''1 = Speaker wise, 2 = Meeting wise'''\n",
    "    stop_words = ['think', 'on', 'not', 'they', \"it's\", 'Oh.', 'Ohh.','people','also', 'from', 'apart', 'There,', 'do', 'your','would', 'i', 'any', 'right?', 'then', 'but', 'yes', 'what', 'one','point','guys', \"i'm\", 'all', 'if', 'in', 'thing', 'was', 'or', 'because','get','now', 'just', 'no', 'my', 'should', 'me', 'could', 'at', 'only','go','giving', 'anything', \"that's\", 'very', \"don't\", 'is', 'can', 'ok',        'know', 'yeah', 'yeah.', 'it', 'are', 'be', 'for', 'this', 'with','kind',        'uh.', 'will', 'yeah,','give','make',\"we'll\",'again','coming','say','hey',        'are', 'of', 'you', 'that', 'we', 'to', 'have', 'a', 'hello', 'Uh','thank',        'Uh,', 'sure.', 'sure', 'So', 'the', 'some', 'some,', 'The.', 'The','see',        'there', \"there's\", 'the', 'Hi', 'hi', 'umm', 'guess', 'Guess', 'oh','got',        'um', 'uh', 'er', 'ah', 'like', 'well', 'and', 'so', 'right','which','something',        'literally', 'okay', 'totally', 'basically', 'actually','them', 'as', 'how',        'out', 'were','maybe','much','want','other','who','these','more','where','our',        'take','done','next','hmm','mmm','things','us','come'] + stopwords.words('english')\n",
    "    if(level == 1):\n",
    "        final_df = pd.DataFrame()\n",
    "        for i in list(df['Speaker_Name'].unique()):\n",
    "            temp_df = df[df['Speaker_Name'] == i].reset_index(drop = True)\n",
    "            word_list = []\n",
    "            for j in range(0, len(temp_df)):\n",
    "                words = list(temp_df['Speaker_text'][j].split(\" \"))\n",
    "                words = list(set(words).difference(stop_words))\n",
    "                top_words = list((dict(sorted(Counter(words).items(), key = itemgetter(1), reverse = True)[:5])).keys())\n",
    "                word_list.append(top_words)\n",
    "            temp_df['Key_Words'] = word_list\n",
    "            final_df = final_df.append(temp_df,ignore_index = True)\n",
    "        return final_df\n",
    "    elif(level == 2):\n",
    "        final_df = pd.DataFrame()\n",
    "        for k in list(df['Meeting_ID'].unique()):\n",
    "            for l in list(df['Group'].unique()):\n",
    "                temp_df = df[(df['Meeting_ID'] == k) & (df['Group'] == l)].reset_index(drop = True)\n",
    "                total_text = temp_df['Speaker_text'].str.strip().str.replace(\",\", \"\").str.replace(\".\", \"\").tolist()\n",
    "                try:\n",
    "                    base = total_text[0]\n",
    "                    for i in range(0, len(total_text)):\n",
    "                        base = base + \" \" + total_text[i]\n",
    "                    words = list(base.lower().split(\" \"))\n",
    "                    filtered_list = []\n",
    "                    for element in words:\n",
    "                        if element not in stop_words:\n",
    "                            filtered_list.append(element)\n",
    "                    x = Counter(filtered_list)\n",
    "                    top_words = pd.DataFrame((dict(sorted(x.items(), key=itemgetter(1), reverse=True)[:10])),index=[0]).T.reset_index().rename(columns={'index': 'Words',0: 'Occurences'})\n",
    "                    top_words['Meeting_ID'] = k\n",
    "                    top_words['Group'] = l\n",
    "                    final_df = final_df.append(top_words,ignore_index = True)\n",
    "                except:\n",
    "                    pass\n",
    "            final_df = final_df.append(top_words,ignore_index = True)\n",
    "            final_df.insert(0,'Meeting_ID',final_df.pop('Meeting_ID'))\n",
    "        return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9efbef59",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:42.874311Z",
     "start_time": "2023-05-17T12:05:42.867201Z"
    }
   },
   "outputs": [],
   "source": [
    "def sentiment_score_assign(df):\n",
    "    sentiment_score = []\n",
    "    for sentence in list(df['Speaker_text']):\n",
    "        fv = [\",\",\".\",\"!\",\"?\",\"-\",\"_\",\"@\",\"#\"]\n",
    "        for val in fv:\n",
    "            sentence = sentence.replace(val,\"\")\n",
    "        blob = TextBlob(sentence)\n",
    "        for sentence in blob.sentences:\n",
    "            score = sentence.sentiment.polarity\n",
    "            sentiment_score.append(score)\n",
    "    df['Sentiment_score'] = sentiment_score\n",
    "    sentiment = []\n",
    "    for i in range(len(df['Sentiment_score'])):\n",
    "        val = df['Sentiment_score'][i]\n",
    "        if val > 0:\n",
    "            sentiment.append('positive')\n",
    "        elif val < 0:\n",
    "            sentiment.append('negative')\n",
    "        else:\n",
    "            sentiment.append('neutral')\n",
    "    df['Sentiment'] = sentiment\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4c178c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:43.234921Z",
     "start_time": "2023-05-17T12:05:43.218107Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_df_generation(folder_path):\n",
    "    file_list = os.listdir(folder_path)\n",
    "    data = []\n",
    "    for file in file_list:\n",
    "        df1 = createtable(folder_path + file)\n",
    "        data.append(df1)\n",
    "    # Concatenating all dataframe to a single dataframe\n",
    "    df = pd.concat(data)\n",
    "    # Sentiment Dataframe generation\n",
    "    temp_df = sentimenttextlength(df)\n",
    "    sentiment_df = sentiment_score_assign(temp_df)\n",
    "    time_df = time_spent(df)\n",
    "    topics_df = pd.read_excel(r\"C:\\Users\\Nareshkumar.T\\OneDrive - GANIT BUSINESS SOLUTIONS PRIVATE LIMITED\\Pulse Check Code\\pc_topics.xlsx\")\n",
    "    sentiment_df = pd.merge(sentiment_df, time_df, on = ['Meeting_ID','Group','Speaker_Name'],  how = 'inner')\n",
    "    sentiment_df = pd.merge(sentiment_df, topics_df, on = 'Meeting_ID', how = 'left')\n",
    "    sentiment_df.insert(1,'Topics_discussed',sentiment_df.pop('Topics Discussed'))\n",
    "    sentiment_df = key_points(sentiment_df,1)\n",
    "    key_df = key_points(sentiment_df,2)\n",
    "    return sentiment_df, key_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4ed4f35",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-05-17T12:05:44.847208Z",
     "start_time": "2023-05-17T12:05:43.603296Z"
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:/Users/Nareshkumar.T/OneDrive - GANIT BUSINESS SOLUTIONS PRIVATE LIMITED/Pulse Check Code/Transcript Documents/'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m sentiment_df, key_df \u001b[38;5;241m=\u001b[39m \u001b[43mfinal_df_generation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mC:/Users/Nareshkumar.T/OneDrive - GANIT BUSINESS SOLUTIONS PRIVATE LIMITED/Pulse Check Code/Transcript Documents/\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[7], line 2\u001b[0m, in \u001b[0;36mfinal_df_generation\u001b[1;34m(folder_path)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfinal_df_generation\u001b[39m(folder_path):\n\u001b[1;32m----> 2\u001b[0m     file_list \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfolder_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     data \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m file_list:\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] The system cannot find the path specified: 'C:/Users/Nareshkumar.T/OneDrive - GANIT BUSINESS SOLUTIONS PRIVATE LIMITED/Pulse Check Code/Transcript Documents/'"
     ]
    }
   ],
   "source": [
    "sentiment_df, key_df = final_df_generation('C:/Users/Nareshkumar.T/OneDrive - GANIT BUSINESS SOLUTIONS PRIVATE LIMITED/Pulse Check Code/Transcript Documents/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "54c611ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-10T12:00:09.821291Z",
     "start_time": "2023-04-10T12:00:09.558203Z"
    }
   },
   "outputs": [],
   "source": [
    "# Storing files to respective directories\n",
    "sentiment_df.to_excel('Pulse_check_data.xlsx')\n",
    "key_df.to_excel(\"Keywords.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0b975e4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T05:30:30.237609Z",
     "start_time": "2023-04-20T05:30:29.413717Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'openai'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mopenai\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'openai'"
     ]
    }
   ],
   "source": [
    "import openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa7c4b5e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-20T05:30:43.136003Z",
     "start_time": "2023-04-20T05:30:35.394680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openaiNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "  Downloading openai-0.27.4-py3-none-any.whl (70 kB)\n",
      "     ---------------------------------------- 70.3/70.3 kB 1.3 MB/s eta 0:00:00\n",
      "Collecting aiohttp\n",
      "  Downloading aiohttp-3.8.4-cp310-cp310-win_amd64.whl (319 kB)\n",
      "     -------------------------------------- 319.8/319.8 kB 3.9 MB/s eta 0:00:00\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (2.28.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from openai) (4.64.1)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (1.26.14)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from requests>=2.20->openai) (2022.12.7)\n",
      "Collecting yarl<2.0,>=1.0\n",
      "  Downloading yarl-1.8.2-cp310-cp310-win_amd64.whl (56 kB)\n",
      "     ---------------------------------------- 56.1/56.1 kB 2.9 MB/s eta 0:00:00\n",
      "Collecting async-timeout<5.0,>=4.0.0a3\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Downloading multidict-6.0.4-cp310-cp310-win_amd64.whl (28 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Downloading frozenlist-1.3.3-cp310-cp310-win_amd64.whl (33 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from aiohttp->openai) (22.1.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\nareshkumar.t\\appdata\\local\\anaconda3\\lib\\site-packages (from tqdm->openai) (0.4.6)\n",
      "Installing collected packages: multidict, frozenlist, async-timeout, yarl, aiosignal, aiohttp, openai\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 multidict-6.0.4 openai-0.27.4 yarl-1.8.2\n"
     ]
    }
   ],
   "source": [
    "pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5f057180",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T06:03:24.321242Z",
     "start_time": "2023-04-21T06:03:24.304564Z"
    }
   },
   "outputs": [],
   "source": [
    "import openai\n",
    "import re\n",
    "import json\n",
    "import pandas as pd\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe64f3bb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T05:23:39.945186Z",
     "start_time": "2023-04-21T05:23:39.926616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Insert API key created in Open AI\n",
    "openai.api_key = \"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\"\n",
    "model_engine = \"gpt-3.5-turbo\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf4041bc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T05:23:46.420337Z",
     "start_time": "2023-04-21T05:23:46.405154Z"
    }
   },
   "outputs": [],
   "source": [
    "text=\"hello I think people might have a couple of points here and they're not specific topic, so let's get started with this and maybe after we are done, we can have 5 minutes for any other comments. Yeah. Gayathri, what do you want to discuss with respect to LinkedIn for employee like? OK, so you have the. Good part of it, like if you engage actively, you know you will get batches. You can post articles, you can write White papers, blogs, everything. What happens to people who don't do that? Like is there any other side of it? Like if you're not actively doing this on LinkedIn, does it have to be a part of your PCA or how does it impact them? Umm. Alright, so yeah, my feedback basically is if there is a carrot, there has to be a stick. That's it. To enforce it. Otherwise some people will do it very actively and the rest 7060% won't do it at all. So yeah, that's the only feedback. Umm. Yep. Yeah. Umm, so there has to. Definitely that should be there, right? Even for the articles that are going on, everything has to go through Raj, as far as I understand right now. So yeah that there. But a good idea. So company wide meetups. I remembered. Uh, there is one thing which can be improved, which is traveling for ganit. It's difficult. You know, you have to fight every time between train and flight, even for an 810 hour journey. That's difficult. I mean, if you're traveling for 10 hours on train overnight, so you're not fresh for client meetings. And also, and I mean, it should be standard policy leaks 506 hundred kilometers. It should be flight, something like that. So. Yeah, I think it can be improved a lot. Even with flights, it's always middle seats and. No food and things like that. So I I really think overall traveling experience for ganit can be improved. Uh. Yeah. Like we see that in every moment or anything that we have, uh, we have to leave our place by three AM, 2:00 AM at night and we cannot come one night before if the meeting is Monday morning. Ideally, I would want to reach by Sunday evening and settle down so that I'm fresh the next day. But those things are not allowed because extra day. So overall it can be improved. I don't know why people are saying here. I talk to my team regularly and there are people who are. Yeah, I had musicians in my team. I had singers in my team. I had people who love to go for bike rides and road trips, and there are so many club ideas here. I want some young people to come up with what they want. It's sports. Sports is huge. In general. I'm a little fish haircut, huh? We have one. Umm. Office Space cup problem name. There's no parking space. But why? Why do we take cab every day when we have our own vehicle? That was the point. I'm a scooter kharida Alexa. I bought a car from. Yeah. We need public speaking clubs and we need to put people in that. No. Thanks, babe.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "449491b5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T05:25:47.445339Z",
     "start_time": "2023-04-21T05:25:46.669128Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "from chennai to bangalore by train or bus.\n",
      "\n",
      "I hope you guys would have something for me to talk about.\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hey, guys to talk on the topic intranet I dont have anything special to talk upon but travlling policy seems to be disappointing for me especially for pepople from chennai it would be great if they provide travel facility\"\n",
    "summary = summarize_text(input_text)\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "7f3874fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T06:03:43.733047Z",
     "start_time": "2023-04-21T06:03:43.725295Z"
    }
   },
   "outputs": [],
   "source": [
    "def summarize_text(input_text):\n",
    "    model_engine = \"curie\"\n",
    "    model_engine_list = [\"curie\",\"ada\",\"davinci\",\"text-davinci-002\",\"babbage\"]    \n",
    "    temp_range = [i/10 for i in range(1, int(1*10)+1)]\n",
    "    max_tokens_range = [i for i in range(10, 50+1, 10)]\n",
    "    response_list = []\n",
    "    model1 = []\n",
    "    max_tokens1 = []\n",
    "    temp1 = []\n",
    "    for model_engine in model_engine_list:\n",
    "        for max_tokens in max_tokens_range:\n",
    "            for temperature in temp_range:\n",
    "                response = openai.Completion.create(engine=model_engine,prompt=input_text,temperature=temperature,max_tokens=max_tokens,)\n",
    "                print(temperature, max_tokens, model_engine)\n",
    "                summary = response.choices[0].text.strip()\n",
    "                print(summary)\n",
    "                model1.append(model_engine)\n",
    "                max_tokens1.append(max_tokens)\n",
    "                response_list.append(summary)\n",
    "                gc.collect()\n",
    "    comparison_df = pd.DataFrame({'Model_engine':model1,'Max_tokens':max_tokens1,'Response':response_list})\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "06d36097",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T06:06:59.912359Z",
     "start_time": "2023-04-21T06:03:46.252615Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1 10 curie\n",
      "to pepople from chennai.\n",
      "0.2 10 curie\n",
      "to pepople from chennai.\n",
      "0.3 10 curie\n",
      "to pepople from chennai also.\n",
      "0.4 10 curie\n",
      "to pepople from chennai in the\n",
      "0.5 10 curie\n",
      "in the form of trains and buses for the p\n",
      "0.6 10 curie\n",
      "to pepople from chennai and also\n",
      "0.7 10 curie\n",
      "for pepople from chennai. I\n",
      "0.8 10 curie\n",
      "for the students.\n",
      "\n",
      "\n",
      "\n",
      "Thanks for your\n",
      "0.9 10 curie\n",
      "from chennai to zamboanga city from\n",
      "1.0 10 curie\n",
      "to chennai so taking the traffic to alleviate\n",
      "0.1 20 curie\n",
      "to pepople from chennai.\n",
      "\n",
      "I am a student of chennai and\n",
      "0.2 20 curie\n",
      "to pepople from chennai and other places in india.\n",
      "0.3 20 curie\n",
      "to pepople from chennai and pepople from other states.\n",
      "\n",
      "I am\n",
      "0.4 20 curie\n",
      "to pepople from chennai.\n",
      "\n",
      "I have been traveling to pune for the\n",
      "0.5 20 curie\n",
      "to pepople from chennai and other places in the state and if they can provide travel\n",
      "0.6 20 curie\n",
      "to pepople from chennai with all the facilities including food and transport.\n",
      "0.7 20 curie\n",
      "to pepple like me and other pepole from chennai and other places to blog\n",
      "0.8 20 curie\n",
      "for us (in chennai) for for other states also like mumbai, hyderabad\n",
      "0.9 20 curie\n",
      "for nonresidents.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "There is train plying from NTPC Jawahar Nag\n",
      "1.0 20 curie\n",
      "(low fare) within chennai as nearly half pepople communicate about where to go for\n",
      "0.1 30 curie\n",
      "to pepople from chennai.\n",
      "\n",
      "I am a student of B.Tech in Computer Science and Engineering. I am currently working as\n",
      "0.2 30 curie\n",
      "to pepople from chennai and other places of tamilnadu.\n",
      "\n",
      "I am a student of a college in chen\n",
      "0.3 30 curie\n",
      "to pepople from chennai so that they can travel to other places like mumbai, delhi, bangalore, hyderabad,\n",
      "0.4 30 curie\n",
      "to these people as they are already in the city and they have to travel to other places for their work or studies.\n",
      "\n",
      "I hope they will\n",
      "0.5 30 curie\n",
      "to chennai people too and also provide a good return policy for the passengers and also provide good facilities and also provide good facilities to the passengers and\n",
      "0.6 30 curie\n",
      "to pepople from chennai so that they can come to pune and enjoy their long awaited holidays.\n",
      "\n",
      "I had a great experience\n",
      "0.7 30 curie\n",
      "for chennai pepople.\n",
      "0.8 30 curie\n",
      "to people from other chennai after chennai in kerala also, it would be great in the same way for people from kerala also\n",
      "0.9 30 curie\n",
      "from other states by air so that we can travel to our schools and the teachers and students can arrange their personal stuff for the journey\n",
      "1.0 30 curie\n",
      "of these countries like chinal,philippi, Singapore, Singapore. and not just Bangladesh, Pakistan or that are easy to reach easily and without\n",
      "0.1 40 curie\n",
      "to pepople from chennai.\n",
      "\n",
      "I have been to many places in India and I have seen many places in India and I have seen many places in India and I have seen many\n",
      "0.2 40 curie\n",
      "to pepople from chennai and pepople from kerala and pepople from tamilnadu and pepople from karnataka and pepople from mahar\n",
      "0.3 40 curie\n",
      "to pepople from chennai and other places in the country.\n",
      "0.4 40 curie\n",
      "to chennai people.\n",
      "0.5 40 curie\n",
      "to people from chennai so that they can go to their native place and enjoy the beauty of nature and their relatives and friends there. I am sure that this will be a great boost for the\n",
      "0.6 40 curie\n",
      "to pepople from chennai and other places and also provide facility to pepople from chennai and other places.\n",
      "0.7 40 curie\n",
      "for their employees. I have always been travelling since last few months to go to Bangalore,Delhi,Hyderabad and I am now getting a travelling facility in my company.\n",
      "\n",
      "I am\n",
      "0.8 40 curie\n",
      "to pepople from chennai in the future there are lot of pepople from chennai who work from outside india but pepople from chennai who work in ind\n",
      "0.9 40 curie\n",
      "for personal trip for me and all other fellow castes and communities with mumbai in whole india\n",
      "\n",
      "if u can post a better topic then plz that would be best\n",
      "\n",
      "hit the\n",
      "1.0 40 curie\n",
      "for me aim is to do some business fir them for any low-level investment simply plzzne thought it was to raise transport\n",
      "0.1 50 curie\n",
      "to pepople from chennai and other places in india.\n",
      "\n",
      "I am a student of B.Tech in Computer Science and Engineering. I am currently working as a software engineer in a MNC. I am a very hard working\n",
      "0.2 50 curie\n",
      "to pepople from chennai to pune which is very near to chennai.\n",
      "\n",
      "I am a student of mumbai and i want to go to pune for my college. I have been to pune many times but\n",
      "0.3 50 curie\n",
      "to pepople from chennai and other places so that they can come and visit us in chennai and other places and also they can come and visit us in chennai and other places and also they can come and visit us in\n",
      "0.4 50 curie\n",
      "to pepople from chennai.\n",
      "\n",
      "I am a newbie in this forum. I am very happy to be here. I am also very happy to be a part of this forum. I have read all the articles in this forum\n",
      "0.5 50 curie\n",
      "for all the people from chennai for their personal use and also for their business needs to get their work done.\n",
      "\n",
      "I have been using the services of this company for years and I am happy to say that they have been very supportive and\n",
      "0.6 50 curie\n",
      "for pepople from chennai.\n",
      "\n",
      "dinesh\n",
      "\n",
      "\n",
      "\n",
      "Posts: 6097\n",
      "\n",
      "From: USA\n",
      "\n",
      "\n",
      "\n",
      "6097USA dinesh\n",
      "\n",
      "\n",
      "\n",
      "Posts: 6097\n",
      "\n",
      "From: USA\n",
      "0.7 50 curie\n",
      "on the weekends in exchange of few days salary per month and can take leave for the beach vacation for two weeks and the salary would be reversed for the year on the basis of the number of days holiday taken by pepople from chennai.\n",
      "0.8 50 curie\n",
      "to more than just this place.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-neha (from chennai)\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "-\n",
      "\n",
      "I too feel that airline policy should be more liberal. I think many of us cannot afford air ticket price, so\n",
      "0.9 50 curie\n",
      "to pepople who are coming from different countries in word to word and it would be alsowel to take the train or bus it would be great if they provide standing facility in nyc which is very important facility and doest seem big\n",
      "1.0 50 curie\n",
      "even within in chennai naturally it would be reasonable to do so but I'm representing pepople from a very big agglomeration with lot of happening whie unable...\n",
      "0.1 10 ada\n",
      "for us to travel to other states in india\n",
      "0.2 10 ada\n",
      "for us to visit the city and also the city\n",
      "0.3 10 ada\n",
      "for people from other parts of india as well\n",
      "0.4 10 ada\n",
      "for all the people who are going to travel to\n",
      "0.5 10 ada\n",
      "for ppl from chennai to new y\n",
      "0.6 10 ada\n",
      "to our customers from chennai\n",
      "\n",
      "23\n",
      "0.7 10 ada\n",
      "for us from chennai\n",
      "\n",
      "Its a\n",
      "0.8 10 ada\n",
      "for flights from chennai also from ch\n",
      "0.9 10 ada\n",
      "on my geography pages but now I was on the\n",
      "1.0 10 ada\n",
      "in the.\n",
      "0.1 20 ada\n",
      "for us to travel to other states like pune, puducherry, karnataka etc\n",
      "0.2 20 ada\n",
      "for us to travel to other parts of india and not just to chennai.\n",
      "0.3 20 ada\n",
      "for us to travel to pune and other cities in pune for the duration of our stay in\n",
      "0.4 20 ada\n",
      "for all their customers.\n",
      "\n",
      "I am not a big fan of the new service but I am\n",
      "0.5 20 ada\n",
      "for the city and chennai so that we can visit chennai and not just visiting the\n",
      "0.6 20 ada\n",
      "to the people from chennai\n",
      "\n",
      "It is a big issue for the city of Chennai and\n",
      "0.7 20 ada\n",
      "for allthe passengers that are from chennai.\n",
      "0.8 20 ada\n",
      "for north indian staff n consumers n if they offer an option for refund ( if you dont like\n",
      "0.9 20 ada\n",
      "for ppl from pepolis to their home country. we live in town and only get to\n",
      "1.0 20 ada\n",
      "on their website. thank you\n",
      "\n",
      "Sent by\n",
      "0.1 30 ada\n",
      "for us to visit the city and also to visit the places we want to visit.\n",
      "\n",
      "I am not sure if they will provide this facility or\n",
      "0.2 30 ada\n",
      "for ppl from chennai to pepose from chennai.\n",
      "\n",
      "I am a student of the University of Pune and I\n",
      "0.3 30 ada\n",
      "for pepople from chennai and other states.\n",
      "\n",
      "I am not a big fan of the new policy of the government of India.\n",
      "0.4 30 ada\n",
      "for us to travel to chennai with no cost. I would like to know if you guys can provide this facility. I am a college student\n",
      "0.5 30 ada\n",
      "for us to travle the country on foot.\n",
      "\n",
      "I would like to know if that is possible in the future or not.\n",
      "0.6 30 ada\n",
      "for Chennai as well as pune.\n",
      "\n",
      "For the first time in my life I am traveling to a new place, I will be staying for\n",
      "0.7 30 ada\n",
      "for ppl from chennai also I am looking for information on how to take a flight from chennai to chicago and if there is\n",
      "0.8 30 ada\n",
      "lot of ppl can use this website as it is just an intranet but as its a few users and no list on the website or policy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 30 ada\n",
      "to henmet , chennai i would encourage them and other people to give this a try as it would make my life as a foreigner and experien\n",
      "1.0 30 ada\n",
      "only to chennai and promote the perturbe in their service from watsapp :\\. Thanks and Best regards, Qasim Paddu\n",
      "0.1 40 ada\n",
      "for us to travel to other states like pune, puducherry, karnataka etc.\n",
      "\n",
      "I am a student of a college in pune and I am looking for a place\n",
      "0.2 40 ada\n",
      "for the chennai area and also for the rest of the country.\n",
      "\n",
      "I am a resident of Chennai and I am looking for a hotel in Chennai. I am looking for a hotel in\n",
      "0.3 40 ada\n",
      "to chennai and also to other cities in india.\n",
      "\n",
      "I am a student of a college in chennai and I am looking for a good place to stay. I am looking\n",
      "0.4 40 ada\n",
      "to the people from different places in the country.\n",
      "\n",
      "I am looking for a good travel agent for the people from chennai.\n",
      "\n",
      "I am looking for a good travel agent for the\n",
      "0.5 40 ada\n",
      "for chennai.\n",
      "0.6 40 ada\n",
      "for people from chennai who want to visit india.\n",
      "\n",
      "Is there any other forum that provides this kind of information.\n",
      "\n",
      "Thanks for your time.\n",
      "0.7 40 ada\n",
      "for hussites from chennai to go to pakistan and other places like india and china it would be great if they dnt charge hussites as much as they do\n",
      "0.8 40 ada\n",
      "and accommodation facility in this part of the country and others such as thailand and india too\n",
      "\n",
      "SammyKMB\n",
      "\n",
      "Hero Member\n",
      "\n",
      "\n",
      "\n",
      "Offline\n",
      "\n",
      "\n",
      "\n",
      "Posts: 2181\n",
      "0.9 40 ada\n",
      ". . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n",
      "1.0 40 ada\n",
      "for OnThaAs.net:Krishni (in voice), Tejaprasanna (SOCIAL MEDIA), RAVENS.....This is my my sincere thanks to them :)\n",
      "0.1 50 ada\n",
      "for us to travel to other places in india.\n",
      "\n",
      "I am a student of a college in Chennai and I am looking for a place to stay for the next few months. I am looking for a place to stay for the next few months\n",
      "0.2 50 ada\n",
      "for all the people from chennai and also for people from other states.\n",
      "\n",
      "I am a native of Chennai and I am a student of University of Chennai. I am a student of University of Chennai and I am a student of University of\n",
      "0.3 50 ada\n",
      "to us and also provide a service to the public in chennai and also to the people of india.\n",
      "\n",
      "I am a student of a college in chennai and I have been travelling to india for the past 2 years.\n",
      "0.4 50 ada\n",
      "for other cities like pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, pune, p\n",
      "0.5 50 ada\n",
      "and services to us, i really like the idea of this website and i hope they will continue to improve this website, i have been using this website for years and i have been using it for about a month now, it is very useful and i\n",
      "0.6 50 ada\n",
      "to us and we can use the internet and have access to the internet as well as the pbs/tv/videos.\n",
      "\n",
      "I am not sure if it is just me but I am in the same boat as many of the other people.\n",
      "0.7 50 ada\n",
      "to option kerala\n",
      "0.8 50 ada\n",
      "for nongtlative people and also for revwhens to visit chennai\n",
      "\n",
      "\n",
      "\n",
      "hope you will have a good time on your trip.\n",
      "0.9 50 ada\n",
      "for thos who wish to visit chennai\n",
      "1.0 50 ada\n",
      "in the ilocos region\n",
      "\n",
      "thanks\n",
      "0.1 10 davinci\n",
      "to chennai and other cities in south ind\n",
      "0.2 10 davinci\n",
      "for pepople from chennai to del\n",
      "0.3 10 davinci\n",
      "from chennai to coimbatore and\n",
      "0.4 10 davinci\n",
      "for pepople from chennai as well\n",
      "0.5 10 davinci\n",
      "in chennai to pune and from p\n",
      "0.6 10 davinci\n",
      "from chennai to bangalore by company itself\n",
      "0.7 10 davinci\n",
      "during weekends for chennai employees and if possible\n",
      "0.8 10 davinci\n",
      "to chennai atleast once a month\n",
      "0.9 10 davinci\n",
      "to senior citizen department and also with discount if we\n",
      "1.0 10 davinci\n",
      "to chennai sitting at a SLON network\n",
      "0.1 20 davinci\n",
      "for chennai to chennai and chennai to coimbatore and coim\n",
      "0.2 20 davinci\n",
      "to chennai and other cities in south india.\n",
      "\n",
      "I am not sure if this\n",
      "0.3 20 davinci\n",
      "to chennai and other cities like bangalore and hyderabad.\n",
      "0.4 20 davinci\n",
      "to chennai or vise versa like they provide to delhi and bangalore.\n",
      "0.5 20 davinci\n",
      "to chennai once in a month.\n",
      "\n",
      "Anyways i have to go now because i\n",
      "0.6 20 davinci\n",
      "for people who live further than 100kms from the office(with an extra charge of course)\n",
      "0.7 20 davinci\n",
      "to chennai on regular basis.\n",
      "\n",
      "I’m not saying that company is not\n",
      "0.8 20 davinci\n",
      "for non computer science people only.\n",
      "\n",
      "TRAVELING POLICY\n",
      "\n",
      "SIN\n",
      "0.9 20 davinci\n",
      "once in a month to chennai by railway.\n",
      "\n",
      "Ex : xxx to chen\n",
      "1.0 20 davinci\n",
      "like if any person wants to travel to a town or a city then there should be certain percentage of\n",
      "0.1 30 davinci\n",
      "to chennai for the people who are working in chennai.\n",
      "\n",
      "I am working in chennai and i have to travel to\n",
      "0.2 30 davinci\n",
      "to chennai.\n",
      "\n",
      "I am not sure if this is the right place to post this, but I am looking for a job in Chennai\n",
      "0.3 30 davinci\n",
      "to chennai as well.\n",
      "\n",
      "I am not sure if this is the right place to post this, but I am looking for a job\n",
      "0.4 30 davinci\n",
      "for pepople in chennai\n",
      "\n",
      "Sreeja\n",
      "\n",
      "Hi,\n",
      "\n",
      "I am from Chennai and I am working in a private\n",
      "0.5 30 davinci\n",
      "for the people who are working for them.\n",
      "\n",
      "Please give me some info about it.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Raju\n",
      "0.6 30 davinci\n",
      "to chennai once a month\n",
      "\n",
      "Thanks\n",
      "0.7 30 davinci\n",
      "to chennai as well.\n",
      "0.8 30 davinci\n",
      "to home cities as a token of grattitude towards employees.\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Rajesh\n",
      "\n",
      "Hi friends,\n",
      "\n",
      "Regarding\n",
      "0.9 30 davinci\n",
      "in night also for...Read More\n",
      "\n",
      "Ramya roy\n",
      "\n",
      "good !!\n",
      "\n",
      "good !!\n",
      "\n",
      "Supriya\n",
      "\n",
      "Yours Truly\n",
      "1.0 30 davinci\n",
      "for us. With regards Prem Vadivel Samyakta, Overseas Jnt Trust Kuniyil Ena Vadivel Mal\n",
      "0.1 40 davinci\n",
      "to chennai and other cities in south india.\n",
      "\n",
      "I have been working in intranet for last 3 years and I have seen many changes in the intranet. I have\n",
      "0.2 40 davinci\n",
      "to chennai.\n",
      "\n",
      "I am not sure if this is the right place to post this, but I am a newbie to the site and I am looking for a good place to start\n",
      "0.3 40 davinci\n",
      "to chennai once in a month.\n",
      "\n",
      "I would like to talk on the topic intranet I dont have anything special to talk upon but travlling policy seems to be disappointing for\n",
      "0.4 40 davinci\n",
      "for people from chennai to chennai and chennai to bangalore and bangalore to chennai and chennai to hyderabad and hyderabad to chennai\n",
      "0.5 40 davinci\n",
      "to chennai people and if they do not provide the facility then they should atleast provide the facility to talk to the customers and know their problems when the customers are not satisfied with the policy\n",
      "0.6 40 davinci\n",
      "for pepople from chennai...\n",
      "\n",
      "Hi,\n",
      "\n",
      "I have joined this company from September 2013 and have completed my probation period. I am from Chennai. I have taken leave to\n",
      "0.7 40 davinci\n",
      "to NCR,Bangalore,Hyderabad,Coimbatore,Mumbai and so on as most of us dont have any intranet with relatives in these places and its bit difficult\n",
      "0.8 40 davinci\n",
      "to those who are working in tamilnadu.\n",
      "\n",
      "Thanks and have a great day.\n",
      "0.9 40 davinci\n",
      "from chennai city or from coimbatore to Chennai or from coimbatore to Mumbai or from Chennai to Kolkatta or from Chennai to Hyderabad or from chennai to\n",
      "1.0 40 davinci\n",
      "for intranet for the people who live outside Chennai and currently working in chennai that would make the shifting over the organisation smooth.\n",
      "\n",
      "Ipod or mp3 player or Laptop would\n",
      "0.1 50 davinci\n",
      "for pepople from chennai to bangalore and back.\n",
      "\n",
      "I am not sure if this is the right place to post this but I am looking for a job in bangalore. I am a fresher and have a btech\n",
      "0.2 50 davinci\n",
      "to chennai and other cities in tamilnadu.\n",
      "\n",
      "I am not sure if this is the right place to post this, but I am looking for a job in Chennai. I have a Bachelors degree in Computer Science\n",
      "0.3 50 davinci\n",
      "to chennai as well.\n",
      "\n",
      "I am working in a company in chennai and i dont have any travel facility to chennai.\n",
      "\n",
      "Thanks\n",
      "\n",
      "Srinivasan\n",
      "0.4 50 davinci\n",
      "for pepople from chennai to coimbatore and back.\n",
      "\n",
      "I would like to know the procedure to apply for the same.\n",
      "\n",
      "Regards,\n",
      "\n",
      "S.Suresh\n",
      "0.5 50 davinci\n",
      "to chennai. I am from chennai and my company provides travel facility to chennai only. I see many people from chennai are working in other states and they are not getting travel facility to chennai. This is\n",
      "0.6 50 davinci\n",
      "to all cities in india may be they can start with chennai to pune, chennai to bangalore and also kolkata to pune and bangalore.\n",
      "\n",
      "\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Naveen\n",
      "0.7 50 davinci\n",
      "to chennai with in a stipulated time period and especially to new employees who are moving from chennai to chennai the travel time is so unneccessary to spend it would be great if they have something like that and i\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8 50 davinci\n",
      "to people who are willing to attend the conferences and workshops please consider the same and provide us a great facilty of travel options like what we have in this year it will be great if we could travel by plane beacuse of my job and lot\n",
      "0.9 50 davinci\n",
      "as soon as possible as a tax payer I feel local pepople have right to know about this.\n",
      "\n",
      "Required skills: For me key skills are Presentation, Soft copy useing Software. Personal skills like being friendly and being dedicated.\n",
      "1.0 50 davinci\n",
      "but then they wont provide so ,it will b a thumbs down. The management was weak in making the listeners understand the policies properly like th our service fellow chetan should have made things more clear even a frip learning account will be great but that\n",
      "0.1 10 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the int\n",
      "0.2 10 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the int\n",
      "0.3 10 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the int\n",
      "0.4 10 text-davinci-002\n",
      "from chennai to bangalore for us.\n",
      "0.5 10 text-davinci-002\n",
      "from chennai to bangalore.\n",
      "0.6 10 text-davinci-002\n",
      "from chennai .\n",
      "\n",
      "There is no\n",
      "0.7 10 text-davinci-002\n",
      "from chennai to hyderabad and vice\n",
      "0.8 10 text-davinci-002\n",
      "for their employees through their intranet website or\n",
      "0.9 10 text-davinci-002\n",
      "for all the employees.\n",
      "\n",
      "I will suggest\n",
      "1.0 10 text-davinci-002\n",
      "eg:school and medical allowance etc, rate of\n",
      "0.1 20 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the intranet is a great way to communicate with people\n",
      "0.2 20 text-davinci-002\n",
      "from chennai to bangalore.\n",
      "\n",
      "I think the intranet is a great way\n",
      "0.3 20 text-davinci-002\n",
      "for chennai to mumbai and back.\n",
      "\n",
      "I think the intranet is a\n",
      "0.4 20 text-davinci-002\n",
      "from chennai to bangalore.\n",
      "\n",
      "Thanks\n",
      "0.5 20 text-davinci-002\n",
      "to chennai.\n",
      "0.6 20 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I completely agree with you. I think the company should really look into this\n",
      "0.7 20 text-davinci-002\n",
      "from chennai to other places(not including the mandatory places like kolkata,mumbai\n",
      "0.8 20 text-davinci-002\n",
      "for their employees atleast on the weekends, because most of the people from chennai prefer\n",
      "0.9 20 text-davinci-002\n",
      "for us atleast in after working hours\n",
      "\n",
      "I was thinking of just looking up information on\n",
      "1.0 20 text-davinci-002\n",
      "by AC train. It would reallt help the employees.\n",
      "0.1 30 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the intranet is a great way for people to communicate with each other. It is a great way to\n",
      "0.2 30 text-davinci-002\n",
      "from chennai to bangalore and vice versa.\n",
      "\n",
      "I think you should talk to your boss about this.\n",
      "0.3 30 text-davinci-002\n",
      "to chennai people as well.\n",
      "\n",
      "I think the intranet is a great way to communicate with others in the company. It is\n",
      "0.4 30 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I agree with you, the travel policy is disappointing. I think they should provide travel assistance for us.\n",
      "0.5 30 text-davinci-002\n",
      "for us to go to our native place atleast once in a year.\n",
      "\n",
      "I am sure that there are many people who would agree with\n",
      "0.6 30 text-davinci-002\n",
      "for people like us who are from chennai and the other thing is that the salary seems to be a bit low for the people with 1 year\n",
      "0.7 30 text-davinci-002\n",
      "for weekend trips.\n",
      "\n",
      "Thank you\n",
      "0.8 30 text-davinci-002\n",
      "by train instead of flight by train it is convenient and very cheap to travel from chennai\n",
      "0.9 30 text-davinci-002\n",
      "to employees from chennai.\n",
      "1.0 30 text-davinci-002\n",
      "like if the company is paying for stay or if its your own travel, the company should at least pay for food expenses for all those who are travel\n",
      "0.1 40 text-davinci-002\n",
      "from chennai to bangalore and back.\n",
      "\n",
      "I think that the intranet is a great way to communicate with people in the company. It is a great way to keep people updated\n",
      "0.2 40 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I dont have anything special to talk upon but travlling policy seems to be disappointing for me especially for pepople from chennai it would be great if they provide\n",
      "0.3 40 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I agree with you. I think the travel policy should be improved.\n",
      "0.4 40 text-davinci-002\n",
      "for us as well.\n",
      "0.5 40 text-davinci-002\n",
      "for chennai employees\n",
      "\n",
      "\n",
      "\n",
      "I think this is a great topic for discussion. I have been a big proponent of the intranet for a long time. I think it is a great\n",
      "0.6 40 text-davinci-002\n",
      "for the people like me to visit other places in India or abrod.\n",
      "\n",
      "and I think we can have some sort of frame work for this discussion on intranet.\n",
      "0.7 40 text-davinci-002\n",
      "from chennai to visakhapatnam.\n",
      "0.8 40 text-davinci-002\n",
      "by flight rather than train. i dont think its a good idea to provide train facility for pepole from chennai it would be great if they provide some bus facility to chennai from\n",
      "0.9 40 text-davinci-002\n",
      "for us so as to provide us satisfaction in every form.\n",
      "\n",
      "\n",
      "\n",
      "Thank you\n",
      "1.0 40 text-davinci-002\n",
      "or coupon for balance amount with the intranet protocol thanks\n",
      "0.1 50 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think the intranet is a great way to communicate with people in the company. It is a great way to keep everyone up to date on what is going on in the company.\n",
      "0.2 50 text-davinci-002\n",
      "for us.\n",
      "\n",
      "I think that the intranet is a great way to communicate with others in the company. It is a great way to stay up to date on what is going on in the company and to find out about new products and\n",
      "0.3 50 text-davinci-002\n",
      "for us as well.\n",
      "\n",
      "I think you should talk to your boss about this.\n",
      "0.4 50 text-davinci-002\n",
      "for us to reach the office from our place.\n",
      "0.5 50 text-davinci-002\n",
      "for us to reach the office from our home a comfortable and safe way to reach the office.\n",
      "\n",
      "I think the intranet is a great way to communicate with people in the company. It is a great way to stay in touch with what\n",
      "0.6 50 text-davinci-002\n",
      "from chennai to bangalore,\n",
      "\n",
      "I think they need some improvement in that aspect and it would be great if they consider our problem.\n",
      "\n",
      "Thanks.\n",
      "0.7 50 text-davinci-002\n",
      "for pepole from chennai as well. it would be great if you can expand your wings for us.\n",
      "\n",
      "I have an experience of about 5 years and my current ctc is 5lakhs p.a.\n",
      "0.8 50 text-davinci-002\n",
      "like bus and train pass and also some accomodation facility..for people from chennai because it will be very difficult for us to come up with such a long distance and have to stay at a hotel..\n",
      "0.9 50 text-davinci-002\n",
      "on weekends too.\n",
      "1.0 50 text-davinci-002\n",
      "in slr instead of ftr it also reduces cost and time we are quire near to shell but\n",
      "0.1 10 babbage\n",
      "for pepople from chennai to go\n",
      "0.2 10 babbage\n",
      "for pepople from chennai to go\n",
      "0.3 10 babbage\n",
      "for pepople from chennai to go\n",
      "0.4 10 babbage\n",
      "for pepople from chennai to k\n",
      "0.5 10 babbage\n",
      "to pepole from other cities like Bangalore,\n",
      "0.6 10 babbage\n",
      "for pepole from other places and also provide\n",
      "0.7 10 babbage\n",
      "for pepople from other cities of India ..\n",
      "0.8 10 babbage\n",
      "to pepople from other cities also it would\n",
      "0.9 10 babbage\n",
      "specially via metar over there we will have like\n",
      "1.0 10 babbage\n",
      "even just in one city of bust spreading to all\n",
      "0.1 20 babbage\n",
      "for pepople from chennai to go to other cities like bangalore, hyderabad\n",
      "0.2 20 babbage\n",
      "for pepople from chennai to go to chennai for business purpose.\n",
      "0.3 20 babbage\n",
      "to pepople from other cities like Bangalore, Chennai, Hyderabad, Kolkata, Mumbai\n",
      "0.4 20 babbage\n",
      "for pepole from chennai to chennai for business purpose.\n",
      "\n",
      "I have\n",
      "0.5 20 babbage\n",
      "for pepople from other states like kerala and maharashtra.\n",
      "\n",
      "I am from\n",
      "0.6 20 babbage\n",
      "for pepople from other city for the same reason I will travel with my family to chen\n",
      "0.7 20 babbage\n",
      "to all pepople of chennai specially to pepole from outside chennai.\n",
      "0.8 20 babbage\n",
      ".\n",
      "\n",
      "If you would like to help, you are welcomed by mentioning your interest and required information\n",
      "0.9 20 babbage\n",
      "to indian students and organisations not only in vancouver but also in chennai.\n",
      "1.0 20 babbage\n",
      "so that we can go anywhere in India we can go anywhere in India like Chennai, Bangalore, New\n",
      "0.1 30 babbage\n",
      "for pepople from chennai to go to chennai for business purpose.\n",
      "\n",
      "I am a student from chennai and I\n",
      "0.2 30 babbage\n",
      "for pepople from other cities like Bangalore, Chennai, Hyderabad, Kolkata, Mumbai, Pune, etc.\n",
      "\n",
      "I am\n",
      "0.3 30 babbage\n",
      "to pepole from chennai.\n",
      "\n",
      "I am from chennai and I want to travel to other cities like mumbai, del\n",
      "0.4 30 babbage\n",
      "to pepople from chennai and other cities like mumbai, delhi, bangalore, hyderabad, kolkata, sur\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5 30 babbage\n",
      "for pepople from other states like mumbai or even from other cities like delhi or kolkata.\n",
      "\n",
      "Why cant we travel on\n",
      "0.6 30 babbage\n",
      "to pepople from chennai.\n",
      "\n",
      "Shivji is a brilliant leader and a great person. I very happy to have met him\n",
      "0.7 30 babbage\n",
      "to pepople from Chennai in their conferences\n",
      "\n",
      "\n",
      "\n",
      "Thanks,\n",
      "\n",
      "Venkata\n",
      "\n",
      "pinkpinkpink143 moga\n",
      "0.8 30 babbage\n",
      "like Delhi, New Delhi, Bangalore, Chennai and Hyderabad.\n",
      "\n",
      "\n",
      "\n",
      "In addition if delhi is like chennai then to we can\n",
      "0.9 30 babbage\n",
      "for people from there.\n",
      "\n",
      "Ongoing policy from Google is quite disappointed for me. NO I don’t want to do nothing but\n",
      "1.0 30 babbage\n",
      "in centre. I mean we have so much jussifaction by not being provided during the last couple of years.Our firms also changed very much\n",
      "0.1 40 babbage\n",
      "for pepople from chennai to go to chennai for business purpose.\n",
      "\n",
      "I am a student from chennai and I am planning to go to chennai for business\n",
      "0.2 40 babbage\n",
      "for pepole from other cities like Bangalore, Chennai, Hyderabad, Kolkata, Mumbai, Pune, etc.\n",
      "\n",
      "I am a student from Chennai and I am planning to travel\n",
      "0.3 40 babbage\n",
      "for pepople from chennai.\n",
      "\n",
      "I have a friend who is planning to visit chennai and he is planning to visit chennai airport and he is planning to travel by\n",
      "0.4 40 babbage\n",
      "to pepople from chennai I am a pepole from chennai and I am searching for a job in chennai I am looking for a job in chennai I\n",
      "0.5 40 babbage\n",
      "for pepople from all over India.\n",
      "\n",
      "I have been travelling for a long time, I have been to all the ASIA countries and have been to Kolkata and Chennai. I\n",
      "0.6 40 babbage\n",
      "for pepople from other city and for pepole from other states.\n",
      "\n",
      "I mean it is not only me who has been travelling to other states.\n",
      "\n",
      "I have been travelling to\n",
      "0.7 40 babbage\n",
      "for pepople from chennai to Chennai.\n",
      "0.8 40 babbage\n",
      "to peple from other city I would like to welcome PuMaS in the city for a horney administrator and manager to weave the tour to the city.\n",
      "0.9 40 babbage\n",
      "within national capital region and also within the city of chandigarh.\n",
      "\n",
      "So my question would be India they provide best features in pep stars section However they are not providing travel facility\n",
      "1.0 40 babbage\n",
      "or other Agencies or authorities can anyone help out for them.\n",
      "\n",
      "Members Services\n",
      "0.1 50 babbage\n",
      "for pepople from chennai to go to other cities like bangalore, hyderabad, kolkata, delhi, mumbai, chandigarh, guwahati, etc.\n",
      "\n",
      "I am a student\n",
      "0.2 50 babbage\n",
      "to pepople from other states like kerala, Andhra pradesh, Tamilnadu, Andhra pradesh, Tamilnadu, Andhra pradesh, Tamilnadu, Andhra pradesh, Tamilnadu\n",
      "0.3 50 babbage\n",
      "for pepople from other cities like Bangalore, Chennai, Hyderabad, Kolkata, Mumbai, Pune, etc.\n",
      "\n",
      "I am trying to book my flight ticket to go to chennai for the first time. I have booked\n",
      "0.4 50 babbage\n",
      "for pepople from other cities like bangalore, hyderabad, kolkata, delhi, mumbai, chandigarh, etc.\n",
      "\n",
      "I have seen a lot of people from other cities who are planning to travel\n",
      "0.5 50 babbage\n",
      "to pepople from chennai and also provide free travel facility to pepople from other states.\n",
      "0.6 50 babbage\n",
      "to pepople from chennai and also to outstation pepologists. I want to know if they have any plan to provide travel facility to pepologists from chennai and also to outstation pepologists.\n",
      "0.7 50 babbage\n",
      "and they should be easy to reach\n",
      "\n",
      "\n",
      "\n",
      "from Chennai are the people travelling from chennai to Bangalore?from Bangalore to Chennai are the people travelling from Chennai to Delhi?from Delhi to Bangalore are the people travelling from Bangalore to Chennai?from\n",
      "0.8 50 babbage\n",
      "for pepople from chennai and others in india for some the travel is not very comfortable for them otherwise travelling in mobile and many one is facing so many difficulties because of which pepfrobe want to know the method of travel by\n",
      "0.9 50 babbage\n",
      "to the pepople so its more easier for them to travel to take care the safety of the children and that they might able to travel to other destinations a lot in a short span of time and this is refer to us from the family members who\n",
      "1.0 50 babbage\n",
      "for them and can conduct the class and deal them with on mon-fri\"\n",
      "\n",
      "Pavanveer S Arora 9 days ago\n",
      "\n",
      "\"To the people This ebook template is awesome and simple , Easy, beneficial and accurate. \"\n",
      "    Model_engine  Max_tokens  \\\n",
      "0          curie          10   \n",
      "1          curie          10   \n",
      "2          curie          10   \n",
      "3          curie          10   \n",
      "4          curie          10   \n",
      "..           ...         ...   \n",
      "245      babbage          50   \n",
      "246      babbage          50   \n",
      "247      babbage          50   \n",
      "248      babbage          50   \n",
      "249      babbage          50   \n",
      "\n",
      "                                              Response  \n",
      "0                             to pepople from chennai.  \n",
      "1                             to pepople from chennai.  \n",
      "2                        to pepople from chennai also.  \n",
      "3                       to pepople from chennai in the  \n",
      "4            in the form of trains and buses for the p  \n",
      "..                                                 ...  \n",
      "245  to pepople from chennai and also to outstation...  \n",
      "246  and they should be easy to reach\\n\\n\\n\\nfrom C...  \n",
      "247  for pepople from chennai and others in india f...  \n",
      "248  to the pepople so its more easier for them to ...  \n",
      "249  for them and can conduct the class and deal th...  \n",
      "\n",
      "[250 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Hey, guys to talk on the topic intranet I dont have anything special to talk upon but travlling policy seems to be disappointing for me especially for pepople from chennai it would be great if they provide travel facility\"\n",
    "summary = summarize_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f968fb1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T06:41:03.727839Z",
     "start_time": "2023-04-21T06:35:54.691151Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "158fea970313459eb5ce7bad7ebb296d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Nareshkumar.T\\AppData\\Local\\anaconda3\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Nareshkumar.T\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd12429dbc824eccab78e9683d7a59a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9cf65f10b6524b19b7bf18495617e28a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5df140b0e80b47c08c0eb8d60712c5e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The quick brown fox. I really need this brown fox again…but I'll keep this one around. I'd rather have one of the other two. We're gonna go find out where to eat and keep the other two things…\"\n",
      "\n",
      "\"…And we will see what's next?\"\n",
      "\n",
      "Tian Li glanced down at the brown fox with a confused expression.\n",
      "\n",
      "He couldn't hear the answer to his question, he didn't know whether to give it a miss or laugh or…\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load the pre-trained GPT-2 model and tokenizer\n",
    "model = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6ab24cb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-04-21T06:43:42.860495Z",
     "start_time": "2023-04-21T06:43:34.075256Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hey, guys to talk on the topic intranet I dont have anything special to talk upon but travlling policy seems to be disappointing for me especially for pepople from chennai it would be great if they provide travel facility for these people but these are chennai for us. They are so desperate that chennai will give them a new home and it would be better to try to make the country better then we are without the support of the other countries as well. So\n"
     ]
    }
   ],
   "source": [
    "# Set the maximum length for the generated text\n",
    "max_length = 100\n",
    "\n",
    "# Set the temperature parameter for text generation\n",
    "temperature = 1.0\n",
    "\n",
    "# Set the prompt text for text generation\n",
    "prompt_text = \"Hey, guys to talk on the topic intranet I dont have anything special to talk upon but travlling policy seems to be disappointing for me especially for pepople from chennai it would be great if they provide travel facility\"\n",
    "\n",
    "# Encode the prompt text\n",
    "input_ids = tokenizer.encode(prompt_text, return_tensors='pt')\n",
    "\n",
    "# Generate text using the GPT-2 model\n",
    "output = model.generate(\n",
    "    input_ids,\n",
    "    max_length=max_length,\n",
    "    do_sample=True,\n",
    "    temperature=temperature,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    num_return_sequences=1,\n",
    ")\n",
    "\n",
    "# Decode the generated text and print it\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b6996",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
